# configs/stage2_webdataset_training.yaml
project:
  save_dir: './saved_checkpoints/stage2_cff/'
  use_wandb: true
  wandb_project: 'mantis-stage2'
  wandb_run_name: null # auto-generated if null
  wandb_tags: ['webdataset', 'from-config']

data:
  data_dir: '~/imagenet-1k-wds'
  num_workers: 1
  prefetch_factor: 2
  image_size: 224 # not used in script, but good to have

model:
  type: 'mantis_stage2'
  stage1_checkpoint_path: './saved_checkpoints/stage1_from_config/best_model.pth'
  freeze_stem: true
  resume_stage2_checkpoint: null # Optional path to stage2 checkpoint to resume from
  config:
    # --- Shared & Stage 1 Dependent Params ---
    vib_channels: 48
    stem_channels: 96
    encoder_output_channels: 48 # Final output of FiLMedEncoder, should match vib_channels

    # --- Stage 2 Specific Architecture Params ---
    num_tasks: 5 # 'Animals', 'Vehicles', 'Food', 'Plants', 'Objects'
    
    # Client-side (post-stem) parameters
    task_detector_hidden_dim: 64
    film_gen_hidden_dim: 64

    # Server-side parameters
    decoder_output_channels: 512 # To match ResNet layer2 feature dimension
    
    # These are not currently used by the refactored script but kept for reference
    encoder_blocks: 3
    encoder_architecture: 'convgdn'

training:
  device: 'cuda'
  num_epochs: 100
  batch_size: 3
  grad_accumulation_steps: 5  # Increased from 3 to maintain effective batch size ~240
  use_amp: true
  optimizer:
    main_lr: 0.0001  # Increased from 1e-5 to 1e-4
    backbone_lr: 0.00001  # Increased from 1e-6 to 1e-5
    weight_decay: 0.01
    gradient_clip_val: 1.0
  scheduler:
    type: 'CosineAnnealingLR'
    params:
      eta_min: 0.000001 # Corresponds to main_lr / 100
  loss_weights:
    lambda_task: 1.0
    lambda_downstream: 1.0
    beta_prime: 0.01  # Increased from 0.01 to 0.1 for stronger VIB regularization

logging_and_saving:
  log_freq: 100
  save_freq: 1
  monitor_memory: true
  profile_batches: 0 