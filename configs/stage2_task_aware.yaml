models:
  student_model:
    key: 'mantis_stage2'
    kwargs:
      client_params:
        stem_params:
          input_channels: 3
          output_channels: 128
          num_blocks: 2
        task_detector_params:
          input_feat_dim: 128
          num_tasks: 5
          hidden_dim: 64
        film_gen_params:
          num_tasks: 5
          num_filmed_layers: 3
          channels_per_layer: [256, 256, 256]
          hidden_dim: 64
        filmed_encoder_params:
          input_channels: 128
          output_channels: 256
          num_blocks: 3
          film_bypass: False
      num_tasks: 5
      decoder_params_list:
        - input_channels: 256
          output_channels: 128
          num_blocks: 2
        - input_channels: 256
          output_channels: 128
          num_blocks: 2
        - input_channels: 256
          output_channels: 128
          num_blocks: 2
        - input_channels: 256
          output_channels: 128
          num_blocks: 2
        - input_channels: 256
          output_channels: 128
          num_blocks: 2
      tail_params_list:
        - task_type: 'classification'
          input_channels: 128
          num_classes: 398  # Animals
        - task_type: 'classification'
          input_channels: 128
          num_classes: 52   # Vehicles
        - task_type: 'classification'
          input_channels: 128
          num_classes: 50   # Food
        - task_type: 'classification'
          input_channels: 128
          num_classes: 100  # Plants
        - task_type: 'classification'
          input_channels: 128
          num_classes: 400  # Objects
      vib_channels: 256
    frozen_modules: ['client.stem'] # Freeze shared stem from Stage 1
    forward_hook:
      input: []
      output: ['task_predictions', 'downstream_outputs', 'z_film_likelihoods']

datasets:
  train:
    key: 'imagenet_subgroups_dataset'
    kwargs:
      root: './data/imagenet/train'
      task_definitions: !import_call
        _init:
          module_path: 'src.registry'
          class_name: 'create_imagenet_task_definitions'
      transform: !import_call
        _init:
          module_path: 'src.registry'
          class_name: 'get_imagenet_transforms'
        kwargs:
          is_training: True
          image_size: 224

  val:
    key: 'imagenet_subgroups_dataset'
    kwargs:
      root: './data/imagenet/val'
      task_definitions: !import_call
        _init:
          module_path: 'src.registry'
          class_name: 'create_imagenet_task_definitions'
      transform: !import_call
        _init:
          module_path: 'src.registry'
          class_name: 'get_imagenet_transforms'
        kwargs:
          is_training: False
          image_size: 224

train:
  num_epochs: 50
  batch_size: 32
  log_freq: 100
  
  # Load Stage 1 weights
  src_ckpt: './saved_checkpoints/stage1/best_model.pth'
  
  optimizer:
    key: 'AdamW'
    module_wise_configs:
      - module: 'client.filmed_encoder'
        kwargs:
          lr: 0.00001  # Fine-tune encoder with lower LR
      - module: 'client.task_detector'
        kwargs:
          lr: 0.0001
      - module: 'client.film_generator'
        kwargs:
          lr: 0.0001
      - module: 'server_decoders'
        kwargs:
          lr: 0.0001
      - module: 'server_tails'
        kwargs:
          lr: 0.0001
    kwargs:
      weight_decay: 0.01

  scheduler:
    key: 'CosineAnnealingLR'
    kwargs:
      T_max: 50
      eta_min: 0.000001

  criterion:
    key: 'WeightedSumLoss'
    kwargs:
      sub_terms:
        task_detector_loss:
          criterion:
            key: 'BCELoss'
            kwargs:
              reduction: 'mean'
          criterion_wrapper:
            key: 'SimpleLossWrapper'
            kwargs:
              input:
                is_from_teacher: False
                module_path: '.'
                io: 'task_predictions'
              target:
                uses_label: True
                label_key: 'Y_task'
          weight: 1.0  # lambda_task

        downstream_task_losses:
          criterion:
            key: 'multi_task_downstream_loss'
            kwargs:
              num_tasks: 5
              task_loss_configs:
                - type: 'CrossEntropyLoss'
                  params:
                    reduction: 'mean'
                - type: 'CrossEntropyLoss'
                  params:
                    reduction: 'mean'
                - type: 'CrossEntropyLoss'
                  params:
                    reduction: 'mean'
                - type: 'CrossEntropyLoss'
                  params:
                    reduction: 'mean'
                - type: 'CrossEntropyLoss'
                  params:
                    reduction: 'mean'
          criterion_wrapper:
            key: 'multi_task_criterion_wrapper'
          weight: 1.0

        rate_loss_z_film:
          criterion:
            key: 'vib_loss_stage2'
            kwargs:
              num_pixels_placeholder: 65536
          criterion_wrapper:
            key: 'SimpleLossWrapper'
            kwargs:
              input:
                is_from_teacher: False
                module_path: '.'
                io: 'z_film_likelihoods'
              target:
                uses_label: False
          weight: 0.01  # beta_prime

test:
  test_data_loader_type: 'val'
  log_freq: 500

save:
  checkpoint_interval: 5
  checkpoint_path: './saved_checkpoints/stage2/'

# Evaluation metrics for multi-task setting
eval:
  metrics:
    - key: 'task_detection_accuracy'
      module_path: 'src.evaluation'
      class_name: 'TaskDetectionAccuracy'
    - key: 'downstream_accuracy'
      module_path: 'src.evaluation'
      class_name: 'MultiTaskAccuracy'
    - key: 'compression_rate'
      module_path: 'src.evaluation'
      class_name: 'CompressionRate' 