datasets:
  # Define the LabelChunkedTaskDataset configuration
  imagenet_chunked_tasks: # A unique name for this specific dataset configuration
    name: &imagenet_chunked_tasks_name 'imagenet_chunked_tasks' # Anchor for easy reference
    type: 'LabelChunkedTaskDataset'     # Your custom wrapper class name
    # Common root for the original dataset, if applicable, or specify per split
    root: &original_dataset_root !join [ '~/resources/datasets/', 'ilsvrc2012' ] 
    splits:
      train:
        dataset_id: &train_chunked_id !join [ *imagenet_chunked_tasks_name, '/train' ]
        params: # Parameters for the LabelChunkedTaskDataset constructor for the 'train' split
          original_dataset: # Configuration for the base dataset to be wrapped
            type: 'ImageFolder' # Assuming your framework uses this string to find the ImageFolder class
            params:
              root: !join [ *original_dataset_root, '/train' ]
              transform_params:
                - type: 'RandomResizedCrop'
                  params:
                    size: &input_resolution [ 224, 224 ]
                - type: 'RandomHorizontalFlip'
                  params:
                    p: 0.5
                - &to_tensor_transform
                  type: 'ToTensor'
                  params: {} # ToTensor usually doesn't take params here
                - &normalize_transform
                  type: 'Normalize'
                  params:
                    mean: [ 0.485, 0.456, 0.406 ]
                    std: [ 0.229, 0.224, 0.225 ]
          task_configs: # List of task definitions
            - task_id: 0 # Can be int or string
              original_labels: !python/object/apply:list [!python/object/apply:range [0, 200]] # Classes 0-199 -> Task 0
            - task_id: 1
              original_labels: !python/object/apply:list [!python/object/apply:range [200, 400]] # Classes 200-399 -> Task 1
            - task_id: 2
              original_labels: !python/object/apply:list [!python/object/apply:range [400, 600]] # Classes 400-599 -> Task 2
            - task_id: 3
              original_labels: !python/object/apply:list [!python/object/apply:range [600, 800]] # Classes 600-799 -> Task 3
            - task_id: 4
              original_labels: !python/object/apply:list [!python/object/apply:range [800, 1000]] # Classes 800-999 -> Task 4
          default_task_id: -1      # Optional: For samples not matching any task_config
          default_task_label: -1   # Optional

      val:
        dataset_id: &val_chunked_id !join [ *imagenet_chunked_tasks_name, '/val' ]
        params: # Parameters for the LabelChunkedTaskDataset constructor for the 'val' split
          original_dataset:
            type: 'ImageFolder'
            params:
              root: !join [ *original_dataset_root, '/val' ]
              transform_params:
                - type: 'Resize'
                  params:
                    size: 256
                - type: 'CenterCrop'
                  params:
                    size: *input_resolution
                - *to_tensor_transform
                - *normalize_transform
          task_configs: # Should generally be the same as for training for consistent evaluation
            - task_id: 0
              original_labels: !python/object/apply:list [!python/object/apply:range [0, 200]]
            - task_id: 1
              original_labels: !python/object/apply:list [!python/object/apply:range [200, 400]]
            - task_id: 2
              original_labels: !python/object/apply:list [!python/object/apply:range [400, 600]]
            - task_id: 3
              original_labels: !python/object/apply:list [!python/object/apply:range [600, 800]]
            - task_id: 4
              original_labels: !python/object/apply:list [!python/object/apply:range [800, 1000]]
          default_task_id: -1
          default_task_label: -1

# --- Example of how this dataset configuration might be used in a training pipeline ---
# This part would typically be under a 'train:' or 'test:' section in your main experiment config.

# train: # Or a specific training stage, e.g., train_multitask_stage:
#   train_data_loader:
#     dataset_id: *train_chunked_id # Reference the wrapped training dataset
#     random_sample: True
#     batch_size: 64
#     num_workers: 8
#     pin_memory: True
#     # cache_output: # Optional, if your framework supports it

#   val_data_loader:
#     dataset_id: *val_chunked_id # Reference the wrapped validation dataset
#     random_sample: False
#     batch_size: 128
#     num_workers: 8
#     pin_memory: True

#   # ... other training configurations like optimizer, scheduler, criterion, model, etc.
